{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from chemistry import Molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/molecules.pickle', 'rb') as f:\n",
    "    molecules = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = pd.read_feather('../data/structures.feather')\n",
    "labelled = pd.read_feather('../data/train.feather')\n",
    "unlabelled = pd.read_feather('../data/test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: dsgdb9nsd_000001\n",
       "Atoms:\n",
       "  C 0: [-0.01269814  1.0858041   0.008001  ]\n",
       "  H 1: [ 0.00215042 -0.00603132  0.00197612]\n",
       "  H 2: [1.0117308e+00 1.4637512e+00 2.7657481e-04]\n",
       "  H 3: [-0.54081506  1.4475266  -0.8766437 ]\n",
       "  H 4: [-0.5238136  1.4379326  0.9063973]\n",
       "Bonds:\n",
       "  C(0) - H(1)\n",
       "  C(0) - H(2)\n",
       "  C(0) - H(3)\n",
       "  C(0) - H(4)\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecules['dsgdb9nsd_000001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): Bond(dist=1.0919529, valency=1, strength=411),\n",
       " (0, 2): Bond(dist=1.0919516, valency=1, strength=411),\n",
       " (0, 3): Bond(dist=1.0919464, valency=1, strength=411),\n",
       " (0, 4): Bond(dist=1.0919476, valency=1, strength=411)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecules['dsgdb9nsd_000001'].bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   1  dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   2  dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   3  dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "5   5  dsgdb9nsd_000001             2             3  2JHH   \n",
       "6   6  dsgdb9nsd_000001             2             4  2JHH   \n",
       "7   7  dsgdb9nsd_000001             3             0  1JHC   \n",
       "8   8  dsgdb9nsd_000001             3             4  2JHH   \n",
       "9   9  dsgdb9nsd_000001             4             0  1JHC   \n",
       "\n",
       "   scalar_coupling_constant  \n",
       "0                 84.807602  \n",
       "1                -11.257000  \n",
       "2                -11.254800  \n",
       "3                -11.254300  \n",
       "4                 84.807404  \n",
       "5                -11.254100  \n",
       "6                -11.254800  \n",
       "7                 84.809303  \n",
       "8                -11.254300  \n",
       "9                 84.809502  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs\n",
    "\n",
    "* bond type\n",
    "  * One hot encoding\n",
    "* bond length\n",
    "* atom1 position\n",
    "* atom2 position\n",
    "* atom3 position\n",
    "* atom4 position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def merge(data):\n",
    "    data.copy()\n",
    "    \n",
    "    m0 = data.merge(structures, left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'], suffixes=('0', '0'))\n",
    "    m1 = data.merge(structures, left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'], suffixes=('1', '1'))\n",
    "    \n",
    "    l0 = m0[['x', 'y', 'z']]\n",
    "    l1 = m1[['x', 'y', 'z']]\n",
    "    d = l0 - l1\n",
    "    d2 = d * d\n",
    "    dist2 = d2.x + d2.y + d2.z\n",
    "    dist = dist2.apply(np.sqrt)\n",
    "    dist.name = 'distance'\n",
    "    \n",
    "    merged = data.join(dist)\n",
    "    merged['atom_0'] = m0.atom\n",
    "    merged['atom_1'] = m1.atom\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelled_merged = merge(labelled)\n",
    "unlabelled_merged = merge(unlabelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_dist = min(labelled_merged.distance.min(), unlabelled_merged.distance.min())\n",
    "max_dist = max(labelled_merged.distance.max(), unlabelled_merged.distance.max())\n",
    "\n",
    "min_coeff = labelled_merged.scalar_coupling_constant.min()\n",
    "max_coeff = labelled_merged.scalar_coupling_constant.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offset = min_coeff\n",
    "scale = max_coeff - min_coeff\n",
    "\n",
    "labelled_merged['norm_distance'] = (labelled_merged.distance - min_dist) / (max_dist - min_dist)\n",
    "unlabelled_merged['norm_distance'] = (unlabelled_merged.distance - min_dist) / (max_dist - min_dist)\n",
    "\n",
    "labelled_merged['norm_scc'] = (labelled_merged.scalar_coupling_constant - min_coeff) / (max_coeff - min_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_coeff = labelled.scalar_coupling_constant.min()\n",
    "max_coeff = labelled.scalar_coupling_constant.max()\n",
    "\n",
    "offset = min_coeff\n",
    "scale = max_coeff - min_coeff\n",
    "\n",
    "labelled['norm_scc'] = (labelled.scalar_coupling_constant - min_coeff) / (max_coeff - min_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = labelled.type.unique()\n",
    "atoms = structures.atom.unique()\n",
    "\n",
    "index = 0\n",
    "type_index = {}\n",
    "for t in types:\n",
    "    type_index[t] = index\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "atom_index = {}\n",
    "for a in atoms:\n",
    "    atom_index[a] = index\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_labelled(data, count=None, train_frac=0.7):\n",
    "    n_labelled = count if count is not None else len(labelled)\n",
    "    n_train = int(n_labelled * train_frac)\n",
    "    n_test = n_labelled - n_train\n",
    "    indices = np.arange(0, n_labelled)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_indices = indices[0:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "    \n",
    "    train = data.iloc[train_indices, :]\n",
    "    test = data.iloc[test_indices, :]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def make_input(data):\n",
    "    n = len(data)\n",
    "    \n",
    "\n",
    "    coupling_input = np.zeros((len(types), n), dtype='float32')\n",
    "    atom_input = [None] * 4\n",
    "    for i in range(len(atom_input)):\n",
    "        atom_input[i] = np.zeros((len(atoms), n), dtype='float32')\n",
    "\n",
    "    bond_input = [None] * 3\n",
    "    for i in range(len(bond_input)):\n",
    "        bond_input[i] = np.zeros((3, n), dtype='float32')\n",
    "\n",
    "    for t in type_index:\n",
    "        coupling_input[type_index[t], data.type == t] = 1\n",
    "\n",
    "    for i, row in enumerate(data.itertuples()):\n",
    "        # coupling_input[type_index[row.type], i] = 1\n",
    "        \n",
    "        m = molecules[row.molecule_name]\n",
    "        bonds = m.bonds\n",
    "        \n",
    "        path = m.compute_path(row.atom_index_0, row.atom_index_1)\n",
    "        syms = [m.symbols[idx] for idx in path]\n",
    "        \n",
    "        atom_input[0][atom_index[syms[0]], i]  = 1\n",
    "        \n",
    "        try:\n",
    "            i0 = path[0]\n",
    "            for j, i1 in enumerate(path[1:]):\n",
    "                b = bonds.get((i0, i1), None)\n",
    "                if b is None:\n",
    "                    b = bonds.get((i1, i0), None)\n",
    "                if b is None:\n",
    "                    print(f'Unable to resolve bond - path = {path}, bond = {(i0, i1)})')\n",
    "                    i0 = i1\n",
    "                    continue\n",
    "\n",
    "                j2 = j + 1\n",
    "\n",
    "                bond_input[j][:, i] = [b.dist, b.valency, b.strength]            \n",
    "                atom_input[j2][atom_index[syms[j2]], i] = 1\n",
    "\n",
    "                i0 = i1\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return (coupling_input, atom_input, bond_input)\n",
    "\n",
    "def make_output(data):\n",
    "    n = len(data)\n",
    "    output = np.zeros(n, dtype='float32')\n",
    "    output[:] = data.norm_scc\n",
    "        \n",
    "    return output\n",
    "\n",
    "def combine_inputs(inputs_tuple):\n",
    "    coupling_input, atom_input, bond_input = inputs_tuple\n",
    "    \n",
    "    inputs = [coupling_input]\n",
    "    inputs.extend(atom_input)\n",
    "    inputs.extend(bond_input)\n",
    "    \n",
    "    w, h = coupling_input.shape\n",
    "    for a in atom_input:\n",
    "        w += a.shape[0]\n",
    "    for a in bond_input:\n",
    "        w += a.shape[0]\n",
    "    \n",
    "    input = np.empty((w, h), dtype='float32')\n",
    "    i = 0\n",
    "    for a in inputs:\n",
    "        w, _ = a.shape\n",
    "        input[i:i + w, :] = a\n",
    "        i += w\n",
    "    \n",
    "    return input.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_train, labelled_test = partition_labelled(labelled, 1000)\n",
    "\n",
    "labelled_train_input = combine_inputs(make_input(labelled_train))\n",
    "labelled_train_output = make_output(labelled_train)\n",
    "\n",
    "labelled_test_input = combine_inputs(make_input(labelled_test))\n",
    "labelled_test_output = make_output(labelled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR,LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautham/apps/anaconda3/envs/kaggle-cpu/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7044131948504228"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVR()\n",
    "model.fit(labelled_train_input, labelled_train_output)\n",
    "print('')\n",
    "#print(model.predict(test_input))\n",
    "#print(test_output)\n",
    "model.score(labelled_test_input, labelled_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4658147, 37), (4658147,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_train_input = combine_inputs(make_input(labelled))\n",
    "labelled_train_output = make_output(labelled)\n",
    "\n",
    "labelled_train_input.shape, labelled_train_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautham/apps/anaconda3/envs/kaggle-cpu/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVR()\n",
    "model.fit(labelled_train_input, labelled_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_input = make_input(unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[array([[0., 1., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n list([array([[0., 0., 0., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1., 1., 1., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1., 0., 1., ..., 1., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)])\n list([array([[  1.0620991,   1.0620991,   1.0620991, ...,   1.0804824,\n          1.0804824,   1.0804824],\n       [  1.       ,   1.       ,   1.       , ...,   1.       ,\n          1.       ,   1.       ],\n       [411.       , 411.       , 411.       , ..., 411.       ,\n        411.       , 411.       ]], dtype=float32), array([[  1.199079 ,   0.       ,   1.199079 , ...,   1.5032722,\n          1.5032722,   0.       ],\n       [  3.       ,   0.       ,   3.       , ...,   1.       ,\n          1.       ,   0.       ],\n       [835.       ,   0.       , 835.       , ..., 346.       ,\n        346.       ,   0.       ]], dtype=float32), array([[  0.       ,   0.       ,   1.0620991, ...,   1.5311819,\n          0.       ,   0.       ],\n       [  0.       ,   0.       ,   1.       , ...,   1.       ,\n          0.       ,   0.       ],\n       [  0.       ,   0.       , 411.       , ..., 346.       ,\n          0.       ,   0.       ]], dtype=float32)])].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e2f4fe63376a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munlabelled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munlabelled_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/apps/anaconda3/envs/kaggle-cpu/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/kaggle-cpu/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    198\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m~/apps/anaconda3/envs/kaggle-cpu/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[array([[0., 1., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n list([array([[0., 0., 0., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1., 1., 1., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1., 0., 1., ..., 1., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)])\n list([array([[  1.0620991,   1.0620991,   1.0620991, ...,   1.0804824,\n          1.0804824,   1.0804824],\n       [  1.       ,   1.       ,   1.       , ...,   1.       ,\n          1.       ,   1.       ],\n       [411.       , 411.       , 411.       , ..., 411.       ,\n        411.       , 411.       ]], dtype=float32), array([[  1.199079 ,   0.       ,   1.199079 , ...,   1.5032722,\n          1.5032722,   0.       ],\n       [  3.       ,   0.       ,   3.       , ...,   1.       ,\n          1.       ,   0.       ],\n       [835.       ,   0.       , 835.       , ..., 346.       ,\n        346.       ,   0.       ]], dtype=float32), array([[  0.       ,   0.       ,   1.0620991, ...,   1.5311819,\n          0.       ,   0.       ],\n       [  0.       ,   0.       ,   1.       , ...,   1.       ,\n          0.       ,   0.       ],\n       [  0.       ,   0.       , 411.       , ..., 346.       ,\n          0.       ,   0.       ]], dtype=float32)])].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "unlabelled_output = model.predict(unlabelled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_output = unlabelled_output * scale + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'id':unlabelled.id, 'scalar_coupling_constant':pd.Series(unlabelled_output, index=unlabelled.index)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('../data/pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
