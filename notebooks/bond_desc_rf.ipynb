{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from chemistry import Atom, Bond, Molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/molecules.pickle', 'rb') as f:\n",
    "    molecules = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = pd.read_feather('../data/structures.feather')\n",
    "labelled = pd.read_feather('../data/train.feather')\n",
    "unlabelled = pd.read_feather('../data/test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(data):\n",
    "    data.copy()\n",
    "    \n",
    "    m0 = data.merge(structures, left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'], suffixes=('0', '0'))\n",
    "    m1 = data.merge(structures, left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'], suffixes=('1', '1'))\n",
    "    \n",
    "    l0 = m0[['x', 'y', 'z']]\n",
    "    l1 = m1[['x', 'y', 'z']]\n",
    "    d = l0 - l1\n",
    "    d2 = d * d\n",
    "    dist2 = d2.x + d2.y + d2.z\n",
    "    dist = dist2.apply(np.sqrt)\n",
    "    dist.name = 'distance'\n",
    "    \n",
    "    merged = data.join(dist)\n",
    "    merged['atom_0'] = m0.atom\n",
    "    merged['atom_1'] = m1.atom\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_merged = merge(labelled)\n",
    "unlabelled_merged = merge(unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = min(labelled_merged.distance.min(), unlabelled_merged.distance.min())\n",
    "max_dist = max(labelled_merged.distance.max(), unlabelled_merged.distance.max())\n",
    "\n",
    "min_coeff = labelled_merged.scalar_coupling_constant.min()\n",
    "max_coeff = labelled_merged.scalar_coupling_constant.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = min_coeff\n",
    "scale = max_coeff - min_coeff\n",
    "\n",
    "labelled_merged['norm_distance'] = (labelled_merged.distance - min_dist) / (max_dist - min_dist)\n",
    "unlabelled_merged['norm_distance'] = (unlabelled_merged.distance - min_dist) / (max_dist - min_dist)\n",
    "\n",
    "labelled_merged['norm_scc'] = (labelled_merged.scalar_coupling_constant - min_coeff) / (max_coeff - min_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = labelled.type.unique()\n",
    "atoms = structures.atom.unique()\n",
    "\n",
    "index = 0\n",
    "type_index = {}\n",
    "for t in types:\n",
    "    type_index[t] = index\n",
    "    index += 1\n",
    "\n",
    "atom_index = {}\n",
    "for a in atoms:\n",
    "    atom_index[a] = index\n",
    "    index += 2\n",
    "\n",
    "dist_index = index\n",
    "index += 1\n",
    "\n",
    "columns = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_labelled(data, count=None, train_frac=0.7):\n",
    "    n_labelled = count if count is not None else len(labelled)\n",
    "    n_train = int(n_labelled * train_frac)\n",
    "    n_test = n_labelled - n_train\n",
    "    indices = np.arange(0, n_labelled)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_indices = indices[0:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "    \n",
    "    train = data.iloc[train_indices, :]\n",
    "    test = data.iloc[test_indices, :]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def make_input(data, columns, type_index, atom_index, dist_index):\n",
    "    n = len(data)\n",
    "    input = np.zeros((columns, n), dtype='float32')\n",
    "    \n",
    "    for t in type_index:\n",
    "        input[type_index[t], data.type == t] = 1\n",
    "        \n",
    "    for a in atom_index:\n",
    "        input[atom_index[a], data.atom_0 == t] = 1\n",
    "        input[atom_index[a] + 1, data.atom_1 == t] = 1\n",
    "        \n",
    "    input[dist_index] = data.norm_distance\n",
    "        \n",
    "    return input.T\n",
    "\n",
    "def make_output(data):\n",
    "    n = len(data)\n",
    "    output = np.zeros(n, dtype='float32')\n",
    "    output[:] = data.norm_scc\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_train, labelled_test = partition_labelled(labelled_merged, 30000)\n",
    "\n",
    "labelled_train_input = make_input(labelled_train, columns, type_index, atom_index, dist_index)\n",
    "labelled_train_output = make_output(labelled_train)\n",
    "\n",
    "labelled_test_input = make_input(labelled_test, columns, type_index, atom_index, dist_index)\n",
    "labelled_test_output = make_output(labelled_test)\n",
    "\n",
    "labelled_train_input.shape, labelled_train_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, test_output, ref_output):\n",
    "    types = data.type.unique()\n",
    "    ntypes = len(types)\n",
    "    sum_log_type_errors = 0\n",
    "    for t in types:\n",
    "        type_test_output = test_output[data.type == t]\n",
    "        type_ref_output = ref_output[data.type == t]\n",
    "        nt = len(type_test_output)\n",
    "        type_error = np.abs(type_test_output - type_ref_output).sum() / nt\n",
    "        log_type_error = np.log(type_error)\n",
    "        sum_log_type_errors += log_type_error\n",
    "        \n",
    "    return sum_log_type_errors / ntypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs=8)\n",
    "model.fit(labelled_train_input, labelled_train_output)\n",
    "output = model.predict(labelled_test_input)\n",
    "compute_error(labelled_test, output, labelled_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_train_input = make_input(labelled_merged, columns, type_index, atom_index, dist_index)\n",
    "labelled_train_output = make_output(labelled_merged)\n",
    "\n",
    "labelled_train_input.shape, labelled_train_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_input = make_input(unlabelled_merged, columns, type_index, atom_index, dist_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs=8)\n",
    "model.fit(labelled_train_input, labelled_train_output)\n",
    "unlabelled_output = model.predict(unlabelled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_output = unlabelled_output * scale + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'id':unlabelled.id, 'scalar_coupling_constant':pd.Series(unlabelled_output, index=unlabelled.index)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('../data/pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
