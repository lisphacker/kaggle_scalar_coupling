{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from chemistry import Molecule\n",
    "from util import score\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/molecules_enh.pickle', 'rb') as f:\n",
    "    molecules = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautham/apps/anaconda3/envs/kaggle/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning:\n",
      "\n",
      ".labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structures = pd.read_feather('../data/structures_enh.feather')\n",
    "molecules_df = pd.read_feather('../data/molecules.feather')\n",
    "labelled = pd.read_feather('../data/train.feather')\n",
    "unlabelled = pd.read_feather('../data/test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipole_moments = pd.read_feather('../data/dipole_moments.feather')\n",
    "magnetic_shielding_tensors = pd.read_feather('../data/magnetic_shielding_tensors.feather')\n",
    "mulliken_charges = pd.read_feather('../data/mulliken_charges.feather')\n",
    "potential_energy = pd.read_feather('../data/potential_energy.feather')\n",
    "scalar_coupling_contributions = pd.read_feather('../data/scalar_coupling_contributions.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_enh = labelled.merge(molecules_df, left_on='molecule_name', right_on='molecule_name')\n",
    "#labelled_enh.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_enh = unlabelled.merge(molecules_df, left_on='molecule_name', right_on='molecule_name')\n",
    "#unlabelled_enh.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelled), len(labelled_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_args = dict(dipole_moments=dipole_moments,\n",
    "               magnetic_shielding_tensors=magnetic_shielding_tensors,\n",
    "               mulliken_charges=mulliken_charges,\n",
    "               potential_energy=potential_energy,\n",
    "               scalar_coupling_contributions=scalar_coupling_contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.structures.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_enh.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import NNModel, partition_data\n",
    "\n",
    "print('Running')\n",
    "\n",
    "#data_df = labelled[labelled.type == '1JHC'].head(10)\n",
    "data_df = labelled_enh.head(10)\n",
    "train_df, test_df = partition_data(data_df, train_frac=1)\n",
    "train_df = train_df.copy()\n",
    "        \n",
    "model = NNModel(model_args = dict(molecules=molecules,\n",
    "                                  structures=structures),\n",
    "               **nn_args)\n",
    "#model.corr(train_df, train_df)\n",
    "model.setup_data(train_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.input_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_enh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = labelled_enh.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['molecule_name']].merge(dipole_moments, left_on='molecule_name', right_on='molecule_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, label):\n",
    "    n = 5\n",
    "    \n",
    "    loss = np.array(history.history['scc_loss'], dtype='float32')\n",
    "    val_loss = np.array(history.history['val_scc_loss'], dtype='float32')\n",
    "    \n",
    "    loss_mean = loss.mean()\n",
    "    loss_nstd = n * loss.std()\n",
    "    \n",
    "    val_loss_mean = val_loss.mean()\n",
    "    val_loss_nstd = n * val_loss.std()\n",
    "       \n",
    "#     mn = min(loss_mean - loss_nstd, val_loss_mean - val_loss_nstd)\n",
    "#     mx = min(loss_mean + loss_nstd, val_loss_mean + val_loss_nstd)\n",
    "    mn = loss_mean - loss_nstd\n",
    "    mx = loss_mean + loss_nstd\n",
    "    \n",
    "#     print(loss.min(), loss.max())\n",
    "#     print(val_loss.min(), val_loss.max())\n",
    "#     print(loss_mean, loss_nstd, val_loss_mean, val_loss_nstd)\n",
    "#     print(mn, mx)\n",
    "    \n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.title('Loss for %s' % label)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(mn, mx)\n",
    "    _= plt.legend(['Train','Validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_args = dict(dipole_moments=dipole_moments,\n",
    "               magnetic_shielding_tensors=magnetic_shielding_tensors,\n",
    "               mulliken_charges=mulliken_charges,\n",
    "               potential_energy=potential_energy,\n",
    "               scalar_coupling_contributions=scalar_coupling_contributions,\n",
    "               epochs=100,\n",
    "               learning_rate=0.001,\n",
    "               validation_split=0.3\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-40435bd915eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelled_enh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-40435bd915eb>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(data, count)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### from models import NNModel\n",
    "from models import partition_data, NNModel\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as tfbe\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "# atom_count_ranges = [(1, 10), (11, 15), (16, 20), (21, 25), (26, 30)]\n",
    "# C_count_ranges = [(1, 5), (6, 6), (7, 7), (8, 9)]\n",
    "coupling_types = sorted(labelled_enh.type.unique())[0:1]\n",
    "def test(data, count=5000):\n",
    "    global model\n",
    "    global history\n",
    "    \n",
    "    plt.figure(figsize=(25, 25))\n",
    "    \n",
    "    for i, t in enumerate(coupling_types, 1):    \n",
    "        data_df = data[data.type == t].head(count)\n",
    "\n",
    "        train_df, test_df = partition_data(data_df)\n",
    "\n",
    "        if len(train_df) < 10 or len(test_df) < 10:\n",
    "            continue\n",
    "\n",
    "        print(f'Training {len(train_df)} samples for {t}')\n",
    "\n",
    "        model = NNModel(dict(molecules=molecules, \n",
    "                             structures=structures),\n",
    "                        **nn_args)\n",
    "        history = model.fit(train_df, train_df)\n",
    "        \n",
    "        print(f'Evaluating {len(test_df)} samples')\n",
    "        output, score = model.evaluate(test_df, test_df)\n",
    "        print(f'{t} score: {score} (trained on {len(train_df)} elements)')\n",
    "\n",
    "\n",
    "        plt.subplot(4, 4, 2 * i - 1)\n",
    "        plot_history(history, t)\n",
    "        \n",
    "        #print(output.shape, test_df.values.shape)\n",
    "        #pprint(list(zip(output[0:20, 0], test_df.scalar_coupling_constant[0:20])))\n",
    "\n",
    "        plt.subplot(4, 4, 2 * i)\n",
    "        plt.plot(test_df.scalar_coupling_constant, output, '*')\n",
    "        mn = min(test_df.scalar_coupling_constant.min(), output.min())\n",
    "        mx = min(test_df.scalar_coupling_constant.max(), output.max())\n",
    "\n",
    "        plt.plot([mn, mx], [mn, mx])\n",
    "        plt.title(t)\n",
    "                        \n",
    "    plt.show()\n",
    "        \n",
    "test(labelled_enh, 30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = model.model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = w.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2.min(), w2.max(), w2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.numeric_input_df.columns[np.abs(w.sum(axis=1)) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import partition_data, NNModel\n",
    "\n",
    "def train(data):\n",
    "    models = {}\n",
    "    for t in sorted(data.type.unique()):\n",
    "        train_df = data[data.type == t]\n",
    "        print(f'Training {len(train_df)} samples for {t}')\n",
    "        model = NNModel(dict(molecules=molecules, \n",
    "                             structures=structures),\n",
    "                        None)\n",
    "        models[t] = model\n",
    "        model.fit(train_df, train_df)\n",
    "    \n",
    "    return models\n",
    "\n",
    "models = train(labelled_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_enh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, models):\n",
    "    out_df = None\n",
    "    \n",
    "    for t in sorted(data.type.unique()):\n",
    "        predict_df = data[data.type == t]\n",
    "        print(f'Predicting {len(predict_df)} samples for {t}')\n",
    "        output = models[t].predict(predict_df)\n",
    "        \n",
    "        id = predict_df['id']\n",
    "        out_df_coupling = pd.DataFrame(data={'id':id, 'scalar_coupling_constant':output.flatten()}, index=predict_df.index)\n",
    "        \n",
    "        if out_df is None:\n",
    "            out_df = out_df_coupling\n",
    "        else:\n",
    "            out_df = out_df.append(out_df_coupling).sort_index()\n",
    "\n",
    "    return out_df.sort_index()\n",
    "    \n",
    "#%prun -s cumulative f(unlabelled.head(10000))\n",
    "prediction = predict(unlabelled_enh, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('../data/pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('nn.pickle', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
